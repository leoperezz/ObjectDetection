{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetection_CSExample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing Dependencies"
      ],
      "metadata": {
        "id": "ewFjOB_WgdRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/leoperezz/ObjectDetection"
      ],
      "metadata": {
        "id": "k8bJqbL7f7UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcf6d94-7e9b-4b0c-8b2c-2ac6bf12d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ObjectDetection'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 56 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "KsInYR0sf7RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "SUZzgA1Vf7Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.7.0"
      ],
      "metadata": {
        "id": "CcXPRTbif7MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download training data\n",
        "* We are going to download training data from Kaggle."
      ],
      "metadata": {
        "id": "iL5fLjbYhL_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "spmC6-mhhJ9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "\n",
        "cstrike='https://www.kaggle.com/datasets/lstmkirigaya/cstrike-detection'\n",
        "traffic_detection='https://www.kaggle.com/datasets/saumyapatel/traffic-vehicles-object-detection'\n",
        "\n",
        "od.download('https://www.kaggle.com/datasets/lstmkirigaya/cstrike-detection')"
      ],
      "metadata": {
        "id": "z7NdfUQdf7J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ObjectDetection.utils import reshape_img_and_bboxes\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "\n",
        "def process_label_array(label_array):\n",
        "  '''\n",
        "  This is for YOLOV5 format\n",
        "  converts (label,x_center,y_center,w,h) to (label,ymin,xmin,ymax,xmax)\n",
        "  '''\n",
        "  real_shape=(int(len(label_array)/5),5)\n",
        "  array=np.reshape(label_array,real_shape)\n",
        "  labels_,bboxes_=array[:,0],array[:,1:]\n",
        "  x_c,y_c,w,h=bboxes_[:,0],bboxes_[:,1],bboxes_[:,2],bboxes_[:,3]\n",
        "  ymin,xmin,ymax,xmax=y_c-h/2,x_c-w/2,y_c+h/2,x_c+w/2\n",
        "  final_array=np.stack([labels_,ymin,xmin,ymax,xmax])\n",
        "  return final_array.T\n",
        "\n",
        "def get_name_txt(path):\n",
        "  '''\n",
        "  Get the name from a file .txt in a path  \n",
        "  '''\n",
        "  x=path.split('/')\n",
        "  x=x[-1].split('.')\n",
        "  x=x[0]\n",
        "  return x\n",
        "\n",
        "def get_array_from_img(img_path):\n",
        "  img=Image.open(img_path)\n",
        "  img=img_to_array(img)\n",
        "  if img.shape[-1]==4:\n",
        "    img=Image.open(img_path)\n",
        "    img=img.convert('RGB')\n",
        "    img=img_to_array(img)  \n",
        "  return img\n",
        "\n",
        "def process_labels(labels,num_classes):\n",
        "  labels_=tf.one_hot(labels,num_classes)\n",
        "  labels_=tf.convert_to_tensor(labels_)\n",
        "  return labels_\n",
        "\n",
        "\n",
        "def handling_png_jpg(images_path,name_img):\n",
        "\n",
        "    try:\n",
        "      img_path=join(images_path,name_img)+'.jpg'\n",
        "      img_array=get_array_from_img(img_path)\n",
        "      return img_path,img_array\n",
        "    except:\n",
        "      img_path=join(images_path,name_img)+'.png'\n",
        "      img_array=get_array_from_img(img_path)\n",
        "      return img_path,img_array\n",
        "\n",
        "def create_dataset(images_path,labels_path,target_size,batch_size,num_classes,size=0.9):\n",
        "  \n",
        "  assert size<=1, 'size must be less or equal than 1'\n",
        "\n",
        "  label_glob=glob(labels_path+'/*.txt')\n",
        "\n",
        "  size_cut=int(len(label_glob)*size)\n",
        "\n",
        "  label_glob=label_glob[:size_cut]\n",
        "\n",
        "  images_list,labels_list,bboxes_list=[],[],[]\n",
        "\n",
        "  for label_path in label_glob:\n",
        "    array=np.fromfile(label_path,sep=' ',dtype='float32')\n",
        "    array=process_label_array(array)\n",
        "    num_objects=array.shape[0]\n",
        "    labels,bboxes=array[:,0],array[:,1:]\n",
        "    labels=process_labels(labels,num_classes)\n",
        "    \n",
        "    name_img=get_name_txt(label_path)\n",
        "\n",
        "    img_path,img_array=handling_png_jpg(images_path,name_img)\n",
        "\n",
        "    img_array,bboxes=reshape_img_and_bboxes(img_array,bboxes,target_size)  \n",
        "    for i in range(num_objects):\n",
        "      images_list.append(img_array)\n",
        "      labels_list.append(labels[i,:])\n",
        "      bboxes_list.append(bboxes[i,:]) \n",
        "\n",
        "  img_tensor=np.stack(images_list)\n",
        "  bboxes_tensor=np.stack(bboxes_list).astype('float32')\n",
        "  labels_tensor=np.stack(labels_list).astype('float32')\n",
        "\n",
        "  data=tf.data.Dataset.from_tensor_slices((img_tensor,bboxes_tensor,labels_tensor))\n",
        "  data=data.batch(batch_size).shuffle(len(label_glob))\n",
        "  data=[[img,bboxes,classes] for (img,bboxes,classes) in data]\n",
        "  print(f'Data Created! size of the data {len(data)*batch_size}')\n",
        "  return data"
      ],
      "metadata": {
        "id": "G3p-b98Hf7HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=32\n",
        "target_size=(224,224)\n",
        "\n",
        "'''For cstrike detection'''\n",
        "\n",
        "images_path='/content/cstrike-detection/images'\n",
        "\n",
        "labels_path='/content/cstrike-detection/labels'\n",
        "\n",
        "num_classes=5\n",
        "\n",
        "size=1\n",
        "t_size=0.9\n",
        "data=create_dataset(images_path,labels_path,target_size,5,num_classes,1)\n",
        "size_train_data=int(len(data)*t_size)\n",
        "train_data,val_data=data[:size_train_data],data[size_train_data:]\n"
      ],
      "metadata": {
        "id": "-leh3Y-rf7BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Creating a model"
      ],
      "metadata": {
        "id": "S9f6n_iRj10c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "metadata": {
        "id": "54tNvKQBjMOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
      ],
      "metadata": {
        "id": "HxiSGwJ1jMKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_path='/content/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
        "ckpt_path='/content/models/research/object_detection/test_data/checkpoint/ckpt-0'\n",
        "\n",
        "configs=config_util.get_configs_from_pipeline_file(config_path)\n",
        "model_config=configs['model']\n",
        "model_config.ssd.num_classes=num_classes\n",
        "model_config.ssd.freeze_batchnorm=True\n",
        "model=model_builder.build(model_config=model_config,is_training=True)"
      ],
      "metadata": {
        "id": "fG3e3dt6jMIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "box_predictor_tmp = tf.compat.v2.train.Checkpoint(\n",
        "    _base_tower_layers_for_heads=model._box_predictor._base_tower_layers_for_heads,\n",
        "    _box_prediction_head=model._box_predictor._box_prediction_head,\n",
        "    )\n",
        "\n",
        "model_tmp = tf.compat.v2.train.Checkpoint(\n",
        "          _feature_extractor=model._feature_extractor,\n",
        "          _box_predictor=box_predictor_tmp)\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=model_tmp)\n",
        "ckpt.restore(ckpt_path).expect_partial()\n",
        "images,shapes=model.preprocess(tf.ones((1,640,640,3)))\n",
        "prediction_dict=model.predict(images,shapes)\n",
        "_=model.postprocess(prediction_dict,shapes)"
      ],
      "metadata": {
        "id": "HcfhE_9yjMDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Looking the variables'''\n",
        "\n",
        "for i in model.trainable_variables:\n",
        "  print(i.name)"
      ],
      "metadata": {
        "id": "IC4EHI2Wl-aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefixes_to_train = [\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
        "\n",
        "trainable_variables = model.trainable_variables\n",
        "to_fine_tune = []\n",
        "\n",
        "for var in trainable_variables:\n",
        "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
        "    to_fine_tune.append(var)"
      ],
      "metadata": {
        "id": "ptXFmcg_l-XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training the model\n",
        "\n",
        "* The shape of the data needs to be: \n",
        "* image:(batch_size,H,W,3)\n",
        "* bboxes: (batch_size,4)\n",
        "* labels: (batch_size,num_classes)\n"
      ],
      "metadata": {
        "id": "YicRZXZzm6p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ObjectDetection.utils import get_train_step_func,get_val_func\n",
        "from ObjectDetection.utils import train_on_ds,val_on_ds\n",
        "\n",
        "optimizer=tf.keras.optimizers.SGD(1e-3,momentum=0.9)\n",
        "train_func=get_train_step_func(model,to_fine_tune,optimizer)\n",
        "val_func=get_val_func(model)"
      ],
      "metadata": {
        "id": "s168G-iomw7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "history={'train_loss':[],'test_loss':[]}\n",
        "loss_reference=np.inf\n",
        "with tf.device('/GPU:0'):\n",
        "  for epoch in range(1,epochs+1):\n",
        "    train_loss=train_on_ds(train_func,train_data)\n",
        "    test_loss=val_on_ds(val_func,val_data)\n",
        "    if test_loss<loss_reference:\n",
        "      loss_reference=test_loss\n",
        "      ckpt=tf.train.Checkpoint(model=model)\n",
        "      ckpt.save('ckpt_counter_strike')\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    print(f'epoch:{epoch} train_loss:{train_loss} test_loss:{test_loss}')\n"
      ],
      "metadata": {
        "id": "pIorfUhzmw4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig=plt.figure()\n",
        "fig.set_size_inches((10,10))\n",
        "plt.plot(np.array(history['train_loss']),label='train loss')\n",
        "plt.plot(np.array(history['test_loss']),label='test loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "3FKTfJnR1t-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Testing the model for two instances:\n",
        "* Using a model with the less train loss\n",
        "* Using a model with the less test loss"
      ],
      "metadata": {
        "id": "OaWwrQhlA3R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ObjectDetection.utils import create_frame_video\n",
        "import os\n",
        "\n",
        "frames_video_path='/content/FramesVideo'\n",
        "video_path='/content/video_real_cs.mp4'\n",
        "name_frame='FRAME'\n",
        "create_frame_video(video_path,name_frame,frames_video_path)"
      ],
      "metadata": {
        "id": "M9VdSdSql-UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img\n",
        "from ObjectDetection.utils import create_array_from_images_path\n",
        "\n",
        "test_data=create_array_from_images_path(frames_video_path,name_frame,target_size,size_min=1)"
      ],
      "metadata": {
        "id": "Io7WNvYFl-RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ObjectDetection.utils import make_category_index\n",
        "\n",
        "classes=['N', 'C', 'D', 'T', 'W']\n",
        "category_index=make_category_index(classes)\n",
        "\n",
        "category_index"
      ],
      "metadata": {
        "id": "Yv_CTw9b-Cra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Model with less train loss"
      ],
      "metadata": {
        "id": "PUTvhPm7Bg6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ObjectDetection.utils import create_images_postprocess,create_video\n",
        "\n",
        "prediction_v1='/content/Predictions/v1'\n",
        "name_frame='POST_FRAME'\n",
        "create_images_postprocess(model,test_data,prediction_v1,name_frame,(10,20),0.3,category_index)\n",
        "images_post_v1=create_array_from_images_path(prediction_v1,name_frame,(224,224),1)\n",
        "create_video(images_post_v1,'video_cs_v1')"
      ],
      "metadata": {
        "id": "YPbEX-qZjLZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Model with less test loss"
      ],
      "metadata": {
        "id": "OkRjerKhCuQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_ckpt=tf.train.Checkpoint(model=model)\n",
        "model_ckpt.restore('/content/ckpt_counter_strike-1')\n",
        "images,shapes=model.preprocess(tf.ones((1,640,640,3)))\n",
        "prediction_dict=model.predict(images,shapes)\n",
        "_=model.postprocess(prediction_dict,shapes)\n",
        "\n",
        "prediction_v1='/content/Predictions/v2'\n",
        "name_frame='POST_FRAME'\n",
        "create_images_postprocess(model,test_data,prediction_v1,name_frame,(10,20),0.3,category_index)\n",
        "images_post_v1=create_array_from_images_path(prediction_v1,name_frame,(224,224),1)\n",
        "create_video(images_post_v1,'video_cs_v2')"
      ],
      "metadata": {
        "id": "FOXnkVOv71NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "88msxCa69L-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b77a6d7-245b-401b-f51c-6b690ddd529b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/video_cs_v1.mp4 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "h1l0FAX-9L6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/video_cs_v2.mp4 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "44bvb3679L3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}